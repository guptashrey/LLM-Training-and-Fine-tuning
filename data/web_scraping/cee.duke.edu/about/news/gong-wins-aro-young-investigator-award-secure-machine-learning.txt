

Skip to main content

  * Departments & Centers
    * Overview
    * Biomedical Engineering
    * Civil & Environmental Engineering
    * Electrical & Computer Engineering
    * Mechanical Engineering & Materials Science
    * Institute for Enterprise Engineering
  * Alumni & Parents
    * Overview
    * Alumni
    * Parents
    * Giving
    * Board of Visitors
    * Our History
    * Email Newsletter
    * Meet the Team
  * Corporate Partners
    * Overview
    * Partners & Sponsors
    * Data Science & AI Industry Affiliates
    * Connect With Students
    * Recruiting Our Students
    * Sponsored Research
    * TechConnect Career Networking
  * Apply
  * Careers
  * Directory

  * Undergraduate
    *       1. For Prospective Students
        1. Majors & Minors
        2. Certificates
        3. General Degree Requirements
        4. 4+1: BSE+Master's Degree
        5. Campus Tours
        6. How to Apply

      2. First-Year Design
      3. Student Entrepreneurship
      4. Undergraduate Research
      5. Where Our Undergrads Go
      6. Diversity, Equity & Inclusion
      7. For Current Students
        1. The First Year
        2. Advising
        3. Student Clubs & Teams
        4. Graduation with Distinction
        5. Internships
        6. Policies & Procedures

  * Graduate
    *       1. For Prospective Students
        1. PhD Programs
        2. Master's Degrees
        3. Online Specializations, Certificates and Short Courses
        4. Admissions Events
        5. How to Apply

      2. For Admitted Students
      3. Diversity, Equity & Inclusion
        1. Bootcamp for Applicants
        2. Recruiting Incentives

      4. For Current Grad Students
        1. Graduate Student Programs & Services

  * Faculty & Research
    *       1. Faculty
        1. Faculty Profiles
        2. New Faculty
        3. Awards and Recognition
        4. NAE Members

      2. Research
        1. Signature Research Themes
        2. Recent External Funding Awards
        3. Faculty Entrepreneurship
        4. Duke Engineering Discoveries

  * About
    *       1. Dean's Welcome
      2. Campus & Tours
      3. Facts & Rankings
      4. Diversity, Equity & Inclusion
      5. Service to Society
      6. Entrepreneurship
      7. Governance
      8. News & Media
        1. Latest News
        2. Podcast
        3. Email Newsletter
        4. Publications
        5. Media Coverage
        6. Public Health Information

      9. Events
        1. Events Calendar
        2. Academic Calendar
        3. Commencement

      10. Art @ Duke Engineering

## You are here

Home » About » News & Media

# Gong Wins ARO Young Investigator Award to Secure Machine Learning

April 21, 2021 | By Ken Kingery

Award will support efforts to build machine learning methods that are provably
secure against multiple types of attacks

Neil Gong, assistant professor of electrical and computer engineering at Duke
University, has won an Army Research Office Young Investigator Award, which
recognizes outstanding young university faculty members by supporting their
research and to encouraging their teaching and research careers. The three-
year, $360,000 award will support Gong’s efforts to build machine learning
methods that are provably secure against adversarial examples and poisoning
attacks.

As machine learning algorithms continue to mature, they are being used in more
and more commonplace applications. While their adoption brings great
opportunities for advancement in a wide variety of fields, it also brings new
opportunities for hackers to manipulate their performance.

At their core, the basic function of machine learning algorithms is to teach
themselves to find distinguishing characteristics to classify data. For
example, researchers are creating algorithms that distinguishimages of stop
signs from speed limit signs, flag emails containing malware in an overloaded
inbox, and spot cellular patterns associated with various types of cancer. To
achieve these outcomes, algorithms must be fed training data consisting of
examples of what they’re learning to find.

> "The attacker’s goal is to force the algorithm to make an incorrect
> classification. This project’s goal is to develop training techniques that
> can secure against these types of attacks and guarantee that the resulting
> AI will make correct predictions."

According to Gong, there are two primary ways that bad actors might try to
interfere with this process. In a poisoning attack, incorrect examples are
inserted into the training data so that the machine learning algorithm’s
learning process is led astray. Imagine a specific line of code designating
emails “safe” being slipped into training data, tricking the algorithm into
misclassifying messages carrying that code—even if the message contains
malware. Adversarial examples, meanwhile, are slightly altered in a specific
way so as to make machine learning algorithms make a mistake—sort of like an
optical illusions for machines.

“In both cases, the attacker’s goal is to force the algorithm to make an
incorrect classification,” said Gong. “This project’s goal is to develop
training techniques that can secure against these types of attacks and
guarantee that the resulting AI will make correct predictions.”

One approach Gong is pursuing is called randomized smoothing. By putting
random noise into the training samples and having a variety of algorithms
“vote” on the correct answer, the process is more secure because the final
classification is an average of multiple solutions. With enough research and
training data, scientists will be able to develop machine learning programs
that can be mathematically proven to be secure against these types of attacks,
according to Gong.”

“In areas of traditional cybersecurity such as detecting malware, people are
always trying to find ways to evade a security classifier, so this research is
immediately applicable to that effort,” said Gong. “As far as people using
stickers on traffic signs to fool self-driving vehicles, that’s a more
futuristic problem that isn’t impacting people’s lives just yet, but we’re
always trying to address potential problems before they actually happen.”

outrageously ambitious

  *   *   *   *   *

© Copyright 2011-2023 Duke University | Pratt Intranet

